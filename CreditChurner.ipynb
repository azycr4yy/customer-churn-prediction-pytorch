{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTK5jryHwdUiRO+hJRS+8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azycr4yy/customer-churn-prediction-pytorch/blob/main/CreditChurner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "zxutgBzcp3BB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import nn, optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"BankChurners.csv\",index_col=False)"
      ],
      "metadata": {
        "id": "l6_rVSfSqN1p"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y_r4HVweqmDb",
        "outputId": "aed456f2-4d01-4603-891b-c58679dd2be7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Gender',\n",
            "       'Dependent_count', 'Education_Level', 'Marital_Status',\n",
            "       'Income_Category', 'Card_Category', 'Months_on_book',\n",
            "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
            "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
            "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
            "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
            "       'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
            "       'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['CLIENTNUM',\n",
        "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
        "                  'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n",
        "          inplace=True)"
      ],
      "metadata": {
        "id": "91st1XoRqHIr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk9LPLs1tDCg",
        "outputId": "99e62ddd-c15f-448a-8c54-d2e5d72bbdad"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Attrition_Flag', 'Customer_Age', 'Gender', 'Dependent_count',\n",
            "       'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category',\n",
            "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
            "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
            "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
            "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore' , sparse_output = False).set_output(transform = 'pandas')\n",
        "ohetransform = ohe.fit_transform(data[['Attrition_Flag','Gender','Education_Level','Marital_Status','Card_Category',\"Income_Category\"]])\n",
        "data = pd.concat([data , ohetransform],axis=1).drop(columns=['Gender','Education_Level','Marital_Status','Card_Category','Attrition_Flag',\"Income_Category\"])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sOKmR1B1qUYs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Attrition_Flag_Existing Customer'])\n",
        "y = data['Attrition_Flag_Existing Customer']"
      ],
      "metadata": {
        "id": "xI5xcUuG1b-K"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "y_test , y_train = y_test.to_numpy() , y_train.to_numpy()"
      ],
      "metadata": {
        "id": "RLkpiiYA13sr"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train.to('cpu'))\n",
        "X_test = sc.transform(X_test.to('cpu'))"
      ],
      "metadata": {
        "id": "GBA6VIei2Agn"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = torch.tensor(X_train) , torch.tensor(X_test) , torch.tensor(y_train) , torch.tensor(y_test)\n",
        "X_train , X_test , y_train , y_test = X_train.float() , X_test.float() , y_train.float() , y_test.float()"
      ],
      "metadata": {
        "id": "GaL61ZFI27LG"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJXaZwvd3FJe",
        "outputId": "e73952c0-fc1a-4263-845b-f73afc5f6436"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8101, 38]),\n",
              " torch.Size([2026, 38]),\n",
              " torch.Size([8101]),\n",
              " torch.Size([2026]))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "X_train , X_test , y_train , y_test = X_train.to(device) , X_test.to(device) , y_train.to(device) , y_test.to(device)"
      ],
      "metadata": {
        "id": "iUKLgbte4Dce"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self, *args, **kwargs) -> None:\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.layer1 = nn.Linear(in_features=38,out_features=64)\n",
        "    self.layer2 = nn.Linear(in_features=64,out_features=128)\n",
        "    self.layer3 = nn.Linear(in_features=128,out_features=256)\n",
        "    self.layer4 = nn.Linear(in_features=256,out_features=64)\n",
        "    self.layer5 = nn.Linear(in_features=64,out_features=1)\n",
        "    self.act = nn.ReLU()\n",
        "  def forward(self,x)->torch.Tensor:\n",
        "    x = self.layer1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer5(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "l89nchC-5tA7"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = BinaryClassifier().to(device)\n",
        "model_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Tr9D-U729o",
        "outputId": "b06c6415-af4f-4b3c-da20-bf5e53b7f538"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BinaryClassifier(\n",
              "  (layer1): Linear(in_features=38, out_features=64, bias=True)\n",
              "  (layer2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (layer3): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (layer4): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (layer5): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (act): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_1.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "UgT1Ea-67ADJ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AI did this No idea what happening lol\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    # print(f\"accuracy_score: y_true shape: {y_true.shape}, dtype: {y_true.dtype}\")\n",
        "    # print(f\"accuracy_score: y_pred shape: {y_pred.shape}, dtype: {y_pred.dtype}\")\n",
        "    # # Print first few values\n",
        "    # print(f\"accuracy_score: y_true[:5]: {y_true[:5]}\")\n",
        "    # print(f\"accuracy_score: y_pred[:5]: {y_pred[:5]}\")\n",
        "\n",
        "\n",
        "    # Ensure y_true has the same shape as y_pred for comparison\n",
        "    original_y_true_shape = y_true.shape\n",
        "    if y_true.shape != y_pred.shape:\n",
        "        if y_true.dim() == 1 and y_pred.dim() == 2 and y_true.shape[0] == y_pred.shape[0]:\n",
        "            y_true = y_true.unsqueeze(1)\n",
        "            # print(f\"accuracy_score: y_true unsqueezed to shape: {y_true.shape}\")\n",
        "        else:\n",
        "            raise ValueError(\"Incompatible shapes for accuracy calculation\")\n",
        "\n",
        "    # Convert to consistent data type (e.g., long integers) for exact comparison\n",
        "    y_true_int = y_true.long()\n",
        "    y_pred_int = y_pred.long()\n",
        "    # print(f\"accuracy_score: y_true_int shape: {y_true_int.shape}, dtype: {y_true_int.dtype}\")\n",
        "    # print(f\"accuracy_score: y_pred_int shape: {y_pred_int.shape}, dtype: {y_pred_int.dtype}\")\n",
        "    # # Print first few values after casting\n",
        "    # print(f\"accuracy_score: y_true_int[:5]: {y_true_int[:5]}\")\n",
        "    # print(f\"accuracy_score: y_pred_int[:5]: {y_pred_int[:5]}\")\n",
        "\n",
        "\n",
        "    # Calculate the number of correct predictions\n",
        "    comparison_result = (y_true_int == y_pred_int)\n",
        "    # print(f\"accuracy_score: comparison_result shape: {comparison_result.shape}, dtype: {comparison_result.dtype}\")\n",
        "    # print(f\"accuracy_score: comparison_result[:5]: {comparison_result[:5]}\")\n",
        "\n",
        "    correct_predictions = comparison_result.sum().item()\n",
        "    # print(f\"accuracy_score: correct_predictions: {correct_predictions}\")\n",
        "\n",
        "\n",
        "    # Calculate accuracy\n",
        "    total_samples = len(y_pred_int)\n",
        "    # print(f\"accuracy_score: total_samples (len(y_pred_int)): {total_samples}\")\n",
        "    acc = (correct_predictions / total_samples) * 100\n",
        "    # print(f\"accuracy_score: calculated acc: {acc}\")\n",
        "\n",
        "\n",
        "    # Revert y_true shape if it was unsqueezed (optional, for clarity if needed later)\n",
        "    # y_true = y_true.view(original_y_true_shape)\n",
        "\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "et8OjI_kOM7V"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "epochs = 10000\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "  y_log = model_1(X_train)\n",
        "  y_label = torch.sigmoid(y_log)\n",
        "  loss = loss_fn(y_log,y_train.unsqueeze(1).float())\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    y_test_log = model_1(X_test)\n",
        "    y_test_label = torch.sigmoid(y_test_log)\n",
        "    y_test_pred = torch.round(y_test_label)\n",
        "    acc = accuracy_score(y_test,y_test_pred)\n",
        "  if epoch%1000==0: # Changed back to 1000 for less verbose output during diagnosis\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss.item()} | Accuracy: {acc}\")"
      ],
      "metadata": {
        "id": "nEy991x_8Qzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba39304-d23e-40b2-a47e-83c3db4b649a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.6855131983757019 | Accuracy: 83.85982230997038\n",
            "Epoch: 1000 | Loss: 0.0001067182602128014 | Accuracy: 100.0\n",
            "Epoch: 2000 | Loss: 3.212456431356259e-05 | Accuracy: 100.0\n",
            "Epoch: 3000 | Loss: 1.4268033737607766e-05 | Accuracy: 100.0\n",
            "Epoch: 4000 | Loss: 7.322742021642625e-06 | Accuracy: 100.0\n",
            "Epoch: 5000 | Loss: 4.12806230087881e-06 | Accuracy: 100.0\n",
            "Epoch: 6000 | Loss: 2.392238229731447e-06 | Accuracy: 100.0\n",
            "Epoch: 7000 | Loss: 1.4417646525544114e-06 | Accuracy: 100.0\n",
            "Epoch: 8000 | Loss: 8.293309861073794e-07 | Accuracy: 100.0\n",
            "Epoch: 9000 | Loss: 5.591296599050111e-07 | Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    y_final_logits = model_1(X_test)\n",
        "    y_final_probs = torch.sigmoid(y_final_logits)\n",
        "    y_final_preds = torch.round(y_final_probs)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_true = y_test.cpu().numpy()\n",
        "y_pred = y_final_preds.cpu().numpy()\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHtO6wq3STKt",
        "outputId": "778a10da-fa45-40ae-ee3c-234a3a7d0009"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 327    0]\n",
            " [   0 1699]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       327\n",
            "         1.0       1.00      1.00      1.00      1699\n",
            "\n",
            "    accuracy                           1.00      2026\n",
            "   macro avg       1.00      1.00      1.00      2026\n",
            "weighted avg       1.00      1.00      1.00      2026\n",
            "\n"
          ]
        }
      ]
    }
  ]
}